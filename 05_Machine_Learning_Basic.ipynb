{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Basic\n",
    "<img src=\"pics/canada.jpg\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "1. What is Machine Learning.\n",
    "2. Types of Data.\n",
    "3. Types of Machine Learning.\n",
    "4. Data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is Machine Learning\n",
    "Machine learning is a subset field in field of Artificial Intelligence which aims to create algorithms that can learn from experience or data to solve problems, instead of human explicitly program it to do so.\n",
    "\n",
    "<img src=\"pics/AI-vs-ML-vs-Deep-Learning.png\" width=\"700\" height=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Types of Data\n",
    "Because data is the most important component of doing machine learning project, therefore, let's learn about types of data in the world of machine learning. There are two types of data, Quantitative and Qualitative, each has different ways to dealing with.\n",
    "#### 2.1. Quantitative data\n",
    "We can think about quantitative data as something that we can represent as number or thing that we can measure it objectively (can be counted). There are two types of quatitative data, continuous and discrete. For instance, height, width, length, temperature, humidity and price are continuous data, number of people and age are discrete data.\n",
    "#### 2.2. Qualitative data\n",
    "Qualitative data are about characteristics and descriptors that cannot be easily measure (cannot be counted). For example, gender, color, nation, texture, taste, smell, level of pain and mood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Types of Machine Learning and applications\n",
    "Main types of Machine learning can be divided into 3 types by the ways it learns.\n",
    "\n",
    "<img src=\"pics/types_of_ML.png\" width=\"700\" height=\"350\">\n",
    "\n",
    "#### 3.1. Supervised Learning\n",
    "Supervised learning is a type of machine learning which learns to predict target output from given input features by **learning from example pair of input and output data**, for example, if you want model to predict *age* of people from they *image* you must have images of his/her pair with his/her *age*, and we call this *age* as **labels**.\n",
    "\n",
    "There are two types of supervised learning model, **regression** and **classification**, the only different is that regression outputs **quantitative** value but classification outputs **qualitative** value. As the prior example, is it regression or classification?\n",
    "\n",
    "Examples of Supervised learning:\n",
    "- K-Nearest Neighbors (KNN)  \n",
    "KNN is the simplest algorithm of supervised learning model, the way it works is simple. Imagine that you want to sell your phone to buy a new one, at first you have no idea what price you should set to sell, then you search on the internet to see what price other people set for the same model of the phone you have and you set your price to be the same or close to them. This is exactly what KNN does, it searchs for the closest K samples then output the average value.\n",
    "\n",
    "<img src=\"pics/knn.png\" height=\"800\" width=\"400\">\n",
    "\n",
    "- Linear Regression  \n",
    "The way linear regression works is that it try to draw a single line which represent all of the samples we gave it, by trying to minimize summation of errors between all sample points and the line when error is the distance measure from each sample point to the line. Linear regression is as it name, it's only used for regression problem.\n",
    "\n",
    "<img src=\"pics/linear_regression.png\" width=\"350\">\n",
    "\n",
    "- Logistic Regression  \n",
    "Logistic regression is similar to linear regression except that it's used for classification problem by adding sigmoid function at the tail of linear regression equation, so that it output range changed from (-inf, inf) to (0, 1) and can be used as binary classification.\n",
    "\n",
    "<img src=\"pics/logistic_regression.png\" width=\"800\">\n",
    "\n",
    "- Decision Tree  \n",
    "You can think of decision tree as a serial of if-else conditions node but what interesting is that you aren't the one who decide which feature and what value to be used at each node, but the algorithm looks at the dataset and creates these serial of node on it own.\n",
    "\n",
    "<img src=\"pics/decision_tree.png\" height=\"600\" width=\"500\">\n",
    "\n",
    "- Random Forest  \n",
    "Because decision tree tend to overfit to the datasets, random forest is one way to solve the overfitting problem of decision tree by using multiple trees instead of only one tree, the outputs of each tree are voted to the final output.\n",
    "\n",
    "<img src=\"pics/random_forest.png\" height=\"600\" width=\"500\">\n",
    "\n",
    "- SVM (Support Vector Machine)  \n",
    "SVM is a classification model which works by drawing a line that separate each class with objective to maximize margin between each class. But what interesting about SVM is that it can create non-linear function to separate non-linear data by projecting the data from one space into another space which data in the new space can be separated by linear hyperplane, then compute a linear hyperplane to separate the data then project the data and the hyperplane back into original space, the hyperplane which projected back into original space will be a non-linear function.\n",
    "\n",
    "<img src=\"pics/svm.png\"  height=\"600\" width=\"300\">\n",
    "<img src=\"pics/svm.gif\"  height=\"600\" width=\"300\">\n",
    "\n",
    "#### 3.2. Unsupervised Learning\n",
    "Unsupervised learning is a type of machine learning which learns to cluster data into groups or reduce dimension of data by learning from the data without output pair sample.\n",
    "\n",
    "<img src=\"pics/cluster.png\" height=\"800\" width=\"700\">\n",
    "\n",
    "Examples of cluster algorithms:\n",
    "- K-means cluster\n",
    "- Hierarchical cluster\n",
    "\n",
    "<img src=\"pics/tSNE.gif\" height=\"800\" width=\"400\">\n",
    "\n",
    "Example of dimensional reduction:\n",
    "- PCA (Principal Component Analysis)\n",
    "- LDA (Linear Discriminant Analysis)\n",
    "- GDA (Generalized Discriminant Analysis)\n",
    "- t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "\n",
    "#### 3.3. Reinforcement Learning\n",
    "Reinforcement learning is a type of machine learning which learns to taking suitable action in a given environment to maximize return reward via trial and error process.\n",
    "\n",
    "<img src=\"pics/Reinforcement_learning_diagram.png\" height=\"600\" width=\"300\">\n",
    "\n",
    "Examples of Reinforcement learning:\n",
    "- Q-Learning\n",
    "- Deep Q-Learning\n",
    "- SARSA (State-Action-Reward-State-Action)\n",
    "- DDPG (Deep Deterministic Policy Gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data preprocessing\n",
    "There are various ways to preprocess data depending on types of data and algorithms, some algorithms may require different way of processing but the following are the most common way to process data.\n",
    "\n",
    "#### 4.1. Quantitative data\n",
    "Quantitative data of different features usually have different range, for example, age and income of people are completely in the different range. If we feed this data to the model directly for the model to learn its parameters, it will has hard time learning the parameters. For this reason, it is best practice to normalize or standardize quantitative features of the model to have to the same range or the same distribution.\n",
    "\n",
    "- Standardization:  \n",
    "Standardization is the way to transform a feature to have the same mean of 0 and standard deviation of 1, using the following equations.\n",
    "#### $$x_i = \\frac{x_i - \\bar{x}}{S} \\dotsm (1)$$\n",
    "#### $$\\bar{x} = \\frac{1}{N}\\sum_{i=1}^{N} x_i \\dotsm (2)$$\n",
    "#### $$S = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N} (x_i - \\bar{x})^2} \\dotsm (3)$$\n",
    "Where  \n",
    "$\\bar{x}$: is the mean of the feature.  \n",
    "$S$: is the standard deviation of the feature.\n",
    "\n",
    "- Normalization:  \n",
    "Normalization is means to scale a feature to have values in range of 0 and 1, using the following equation.\n",
    "#### $$x_i = \\frac{x_i - x_{min}}{x_{max} - x_{min}}$$\n",
    "Where  \n",
    "$x_{min}$: is the minimum value of the feature.  \n",
    "$x_{max}$: is the maximum value of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Standardization\n",
    "class Standardization:\n",
    "    def __init__(self, epsilon=1e-9):\n",
    "        \"\"\"\n",
    "        epsilon is a constant value used to avoid division by zero\n",
    "        \"\"\"\n",
    "        # Put your code here\n",
    "        pass\n",
    "\n",
    "    def fit(self, x):\n",
    "        \"\"\"\n",
    "        x is DataFrame or ndarray of shape (batch_size, feature_nums)\n",
    "        \"\"\"\n",
    "        # Put your code here\n",
    "        pass\n",
    "\n",
    "    def transform(self, x):\n",
    "        \"\"\"\n",
    "        x is DataFrame or ndarray of shape (batch_size, feature_nums)\n",
    "        return ndarray\n",
    "        \"\"\"\n",
    "        # Put your code here\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self, x):\n",
    "        \"\"\"\n",
    "        x is DataFrame or ndarray of shape (batch_size, feature_nums)\n",
    "        \"\"\"\n",
    "        self.fit(x)\n",
    "        return self.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Standardization\n",
    "example_scaler = StandardScaler()\n",
    "scaler = Standardization()\n",
    "\n",
    "# x = np.random.normal(loc=5.0, scale=2.0, size=(1, 10))\n",
    "x = np.random.normal(loc=5.0, scale=2.0, size=(1000, 10))\n",
    "x = pd.DataFrame(x)\n",
    "print(\"x mean: {}\".format(np.mean(x)))\n",
    "print(\"x std: {}\".format(np.std(x)))\n",
    "\n",
    "x_example = example_scaler.fit_transform(x)\n",
    "print(\"x_example mean: {:.4f}\".format(np.mean(x_example)))\n",
    "print(\"x_example std: {:.4f}\".format(np.std(x_example)))\n",
    "\n",
    "x_new = scaler.fit_transform(x)\n",
    "print(\"x_new mean: {:.4f}\".format(np.mean(x_new)))\n",
    "print(\"x_new std: {:.4f}\".format(np.std(x_new)))\n",
    "\n",
    "assert x_example.shape == x_new.shape\n",
    "assert np.mean(np.mean(x_example, axis=0) - np.mean(x_new, axis=0)) <= 1e-7\n",
    "assert np.mean(np.std(x_example, axis=0) - np.std(x_new, axis=0)) <= 1e-7\n",
    "assert np.mean(x_example - x_new) <= 1e-7\n",
    "print(\"pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Normalization\n",
    "class Normalization:\n",
    "    def __init__(self, epsilon=1e-9):\n",
    "        \"\"\"\n",
    "        epsilon is a constant value used to avoid division by zero\n",
    "        \"\"\"\n",
    "        # Put your code here\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x):\n",
    "        \"\"\"\n",
    "        x is DataFrame or ndarray of shape (batch_size, feature_nums)\n",
    "        \"\"\"\n",
    "        # Put your code here\n",
    "        pass\n",
    "    \n",
    "    def transform(self, x):\n",
    "        \"\"\"\n",
    "        x is DataFrame or ndarray of shape (batch_size, feature_nums)\n",
    "        return ndarray\n",
    "        \"\"\"\n",
    "        # Put your code here\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, x):\n",
    "        \"\"\"\n",
    "        x is DataFrame or ndarray of shape (batch_size, feature_nums)\n",
    "        \"\"\"\n",
    "        self.fit(x)\n",
    "        return self.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Normalization\n",
    "example_scaler = MinMaxScaler()\n",
    "scaler = Normalization()\n",
    "\n",
    "# x = np.random.normal(loc=5.0, scale=2.0, size=(1, 10))\n",
    "x = np.random.normal(loc=5.0, scale=2.0, size=(1000, 10))\n",
    "x = pd.DataFrame(x)\n",
    "print(\"x max: {}\".format(np.max(x)))\n",
    "print(\"x min: {}\".format(np.min(x)))\n",
    "\n",
    "x_example = example_scaler.fit_transform(x)\n",
    "print(\"x_example max: {:.4f}\".format(np.max(x_example)))\n",
    "print(\"x_example min: {:.4f}\".format(np.min(x_example)))\n",
    "\n",
    "x_new = scaler.fit_transform(x)\n",
    "print(\"x_new max: {:.4f}\".format(np.max(x_new)))\n",
    "print(\"x_new min: {:.4f}\".format(np.min(x_new)))\n",
    "\n",
    "assert x_example.shape == x_new.shape\n",
    "assert np.mean(np.mean(x_example, axis=0) - np.mean(x_new, axis=0)) <= 1e-7\n",
    "assert np.mean(np.std(x_example, axis=0) - np.std(x_new, axis=0)) <= 1e-7\n",
    "assert np.mean(x_example - x_new) <= 1e-7\n",
    "print(\"pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Qualitative data\n",
    "Because qualitative data is usually represented by strings but most of machine learning require data to be numbers. For this reason, there are several ways to encode the data to be represented by numbers.\n",
    "- Label encoding:  \n",
    "Concept of label enconding is pretty straightforward by encoding each unique string with unique number, for example, let's say you have feature for animals as \"cat\", \"dog\" and \"bird\" you can encode them to be 0, 1 and 2 respectively.\n",
    "\n",
    "<img src=\"pics/label_encoding.png\" width=\"700\">\n",
    "\n",
    "- One-hot encoding:  \n",
    "Encoding categorical data with label encoding is only understandable for human but not for machine, for instance, when we encode \"cat\", \"dog\" and \"bird\" as 0, 1 and 2 respectively, we know that 0 is refer to \"cat\" and 1 is refer to \"dog\" but 0 and 1 have no mathematics relationship, so that \"cat\" is not less than \"dog\" or not similar to \"dog\" than \"bird\", unfortunately this is not the case for machine. Concept of one-hot encoding is to create dummy columns for each class and value in the column would be either 0 or 1 as figure below.\n",
    "\n",
    "<img src=\"pics/onehot_encoder.jpg\" width=\"700\">\n",
    "\n",
    "<img src=\"pics/onehot_encoder-2.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder as ExampleLabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder as ExampleOneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Label encoding\n",
    "class LabelEncoder:\n",
    "    def __init__(self):\n",
    "        # Put your code here\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x):\n",
    "        \"\"\"\n",
    "        x is Series of shape (batch_size, )\n",
    "        \"\"\"\n",
    "        # Put your code here\n",
    "        pass\n",
    "    \n",
    "    def transform(self, x):\n",
    "        \"\"\"\n",
    "        x is Series of shape (batch_size, )\n",
    "        \"\"\"\n",
    "        # Put your code here\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, x):\n",
    "        \"\"\"\n",
    "        x is Series of shape (batch_size, )\n",
    "        \"\"\"\n",
    "        self.fit(x)\n",
    "        return self.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Label encoding\n",
    "example_encoder = ExampleLabelEncoder()\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "x = pd.DataFrame({\"animal\": [\"cat\", \"dog\", \"bird\", \"horse\", \"duck\", \"duck\", \"fox\", \"dog\", \"cat\", \"dog\"],\n",
    "                  \"gender\": [\"male\", \"male\", \"female\", \"male\", \"female\", \"female\", \"male\", \"female\", \"female\", \"male\"]})\n",
    "\n",
    "x_example_1 = example_encoder.fit_transform(x.iloc[:, 0])\n",
    "x_example_2 = example_encoder.fit_transform(x.iloc[:, 1])\n",
    "print(\"x_example_1:\")\n",
    "print(x_example_1)\n",
    "print(\"x_example_2:\")\n",
    "print(x_example_2)\n",
    "print()\n",
    "\n",
    "x_encoded_1 = encoder.fit_transform(x.iloc[:, 0])\n",
    "x_encoded_2 = encoder.fit_transform(x.iloc[:, 1])\n",
    "print(\"x_encoded_1:\")\n",
    "print(x_encoded_1)\n",
    "print(\"x_encoded_2:\")\n",
    "print(x_encoded_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement One-hot encoding\n",
    "class OneHotEncoder:\n",
    "    def __init__(self):\n",
    "        # Put your code here\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x):\n",
    "        \"\"\"\n",
    "        x is Series of shape (batch_size, )\n",
    "        \"\"\"\n",
    "        # Put your code here\n",
    "        pass\n",
    "    \n",
    "    def transform(self, x):\n",
    "        \"\"\"\n",
    "        x is Series of shape (batch_size, )\n",
    "        \"\"\"\n",
    "        # Put your code here\n",
    "        pass\n",
    "    \n",
    "    def fit_transform(self, x):\n",
    "        \"\"\"\n",
    "        x is Series of shape (batch_size, )\n",
    "        \"\"\"\n",
    "        self.fit(x)\n",
    "        return self.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test One-hot encoding\n",
    "example_encoder = ExampleOneHotEncoder()\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "x = pd.DataFrame({\"animal\": [\"cat\", \"dog\", \"bird\", \"horse\", \"duck\", \"duck\", \"fox\", \"dog\", \"cat\", \"dog\"],\n",
    "                  \"gender\": [\"male\", \"male\", \"female\", \"male\", \"female\", \"female\", \"male\", \"female\", \"female\", \"male\"]})\n",
    "\n",
    "x_example_1 = example_encoder.fit_transform(x.iloc[:, 0].to_numpy().reshape(-1, 1))\n",
    "x_example_2 = example_encoder.fit_transform(x.iloc[:, 1].to_numpy().reshape(-1, 1))\n",
    "print(\"x_example_1:\")\n",
    "print(x_example_1.toarray())\n",
    "print(\"x_example_2:\")\n",
    "print(x_example_2.toarray())\n",
    "print()\n",
    "\n",
    "x_encoded_1 = encoder.fit_transform(x.iloc[:, 0])\n",
    "x_encoded_2 = encoder.fit_transform(x.iloc[:, 1])\n",
    "print(\"x_encoded_1:\")\n",
    "print(x_encoded_1)\n",
    "print(\"x_encoded_2:\")\n",
    "print(x_encoded_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
